{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting Dictionary into DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:\n",
      "    one  two\n",
      "a  1.0  1.0\n",
      "b  2.0  2.0\n",
      "c  NaN  3.0\n",
      "d  NaN  4.0\n",
      "e  5.0  NaN\n",
      "After:\n",
      "      one    two\n",
      "a    1.0    1.0\n",
      "b    2.0    2.0\n",
      "c -999.0    3.0\n",
      "d -999.0    4.0\n",
      "e    5.0 -999.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_21768\\2138744124.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  table['two'].fillna(-999,inplace = True)\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "data = {'one': pandas.Series([1, 2, 5], \n",
    "                index=['a', 'b', 'e']),\n",
    "        'two': pandas.Series([1, 2, 3, 4], index=['a', 'b', 'c', 'd'])}\n",
    "table = pandas.DataFrame(data)\n",
    "print(\"Before:\\n\",table)\n",
    "table['one'] = table['one'].replace(np.nan, -999) # Replaces null values with -999\n",
    "table['two'].fillna(-999,inplace = True)   \n",
    "print(\"After:\\n\",table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   # Handling categorical variables using get_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Customer_id  Loan_type_Education Loan  Loan_type_Home Loan  \\\n",
      "0            1                     False                 True   \n",
      "1            2                     False                False   \n",
      "2            3                      True                False   \n",
      "3            4                     False                 True   \n",
      "4            5                     False                False   \n",
      "\n",
      "   Loan_type_Personal Loan  Income_25K  Income_30K  Income_35K  Income_40K  \n",
      "0                    False       False        True       False       False  \n",
      "1                     True        True       False       False       False  \n",
      "2                    False       False       False       False       False  \n",
      "3                    False       False       False       False        True  \n",
      "4                    False       False       False        True       False  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = {'Customer_id': pd.Series([1,2,3,4,5]),\n",
    "        'Loan_type': pd.Series(['Home Loan','Personal Loan','Education Loan','Home Loan','Credit Loan']),\n",
    "        'Income': pd.Series(['30K','25K','15K','40K','35K'])}\n",
    "loan_info = pd.DataFrame(data)\n",
    "loan_info = pd.get_dummies(loan_info, prefix_sep='_', drop_first=True)    \n",
    "print(loan_info)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   # Handling categorical variables using LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.0.2-cp37-cp37m-win_amd64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy>=1.14.6 in c:\\users\\shiva\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from scikit-learn) (1.21.6)\n",
      "Collecting scipy>=1.1.0 (from scikit-learn)\n",
      "  Downloading scipy-1.7.3-cp37-cp37m-win_amd64.whl.metadata (2.2 kB)\n",
      "Collecting joblib>=0.11 (from scikit-learn)\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl.metadata (9.2 kB)\n",
      "Downloading scikit_learn-1.0.2-cp37-cp37m-win_amd64.whl (7.1 MB)\n",
      "   ---------------------------------------- 7.1/7.1 MB 2.5 MB/s eta 0:00:00\n",
      "Downloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "   ---------------------------------------- 302.2/302.2 kB 6.2 MB/s eta 0:00:00\n",
      "Downloading scipy-1.7.3-cp37-cp37m-win_amd64.whl (34.1 MB)\n",
      "   ---------------------------------------- 34.1/34.1 MB 3.0 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.3.2 scikit-learn-1.0.2 scipy-1.7.3 threadpoolctl-3.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "   Customer_id       Loan_type Income\n",
      "0            1       Home Loan    30K\n",
      "1            2   Personal Loan    25K\n",
      "2            3  Education Loan    15K\n",
      "3            4       Home Loan    40K\n",
      "4            5     Credit Loan    35K\n",
      "   Customer_id  Loan_type  Income\n",
      "0            0          2       2\n",
      "1            1          3       1\n",
      "2            2          1       0\n",
      "3            3          2       4\n",
      "4            4          0       3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = {'Customer_id': pd.Series([1,2,3,4,5]),\n",
    "        'Loan_type': pd.Series(['Home Loan',\n",
    "                                'Personal Loan',\n",
    "                                'Education Loan',\n",
    "                                'Home Loan',\n",
    "                                'Credit Loan']),\n",
    "        'Income': pd.Series(['30K','25K','15K',\n",
    "                             '40K','35K'])}\n",
    "loan_info = pd.DataFrame(data)\n",
    "print(loan_info)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "loan_info_upd=loan_info.apply(labelencoder.fit_transform) # Encodes categorical variables \n",
    "print(loan_info_upd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   # Handling categorical variables using OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Customer_id       Loan_type Income\n",
      "0            1       Home Loan    30K\n",
      "1            2   Personal Loan    25K\n",
      "2            3  Education Loan    15K\n",
      "3            4       Home Loan    40K\n",
      "4            5     Credit Loan    35K\n",
      "[[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = {'Customer_id': pd.Series([1,2,3,4,5]),\n",
    "        'Loan_type': pd.Series(['Home Loan',\n",
    "                                'Personal Loan',\n",
    "                                'Education Loan',\n",
    "                                'Home Loan',\n",
    "                                'Credit Loan']),\n",
    "        'Income': pd.Series(['30K','25K','15K',\n",
    "                             '40K','35K'])}\n",
    "loan_info = pd.DataFrame(data)\n",
    "print(loan_info)\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "onehotencoder = OneHotEncoder()\n",
    "X = onehotencoder.fit_transform(loan_info).toarray() # returns array of encoded values\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   #  StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.5646401 ],\n",
       "       [-0.27077707],\n",
       "       [-0.33401051],\n",
       "       [-0.79595951],\n",
       "       [ 1.96538718]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "data1 = np.array([[-100.3],\n",
    "                  [27.5], \n",
    "                  [0],\n",
    "                  [-200.9],\n",
    "                  [1000]])\n",
    "standard_scaler = preprocessing.StandardScaler()\n",
    "scaled = standard_scaler.fit_transform(data1) # Scaling and tranformation of array\n",
    "scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   # MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.08377051],\n",
       "       [1.19019069],\n",
       "       [1.1672912 ],\n",
       "       [1.        ],\n",
       "       [2.        ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "data1 = np.array([[-100.3],\n",
    "                  [27.5], \n",
    "                  [0],\n",
    "                  [-200.9],\n",
    "                  [1000]])\n",
    "minmax_scale = preprocessing.MinMaxScaler(feature_range=(1, 2))\n",
    "scaled = minmax_scale.fit_transform(data1)\n",
    "scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   # RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.78482003],\n",
       "       [ 0.21517997],\n",
       "       [ 0.        ],\n",
       "       [-1.57198748],\n",
       "       [ 7.82472613]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "data1 = np.array([[-100.3],\n",
    "                  [27.5], \n",
    "                  [0],\n",
    "                  [-200.9],\n",
    "                  [1000]])\n",
    "robust_scaler = preprocessing.RobustScaler()\n",
    "scaled = robust_scaler.fit_transform(data1)\n",
    "scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   # Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]]\n",
      "[[0.80377277 0.55160877 0.22064351 0.0315205 ]\n",
      " [0.82813287 0.50702013 0.23660939 0.03380134]\n",
      " [0.80533308 0.54831188 0.2227517  0.03426949]\n",
      " [0.80003025 0.53915082 0.26087943 0.03478392]\n",
      " [0.790965   0.5694948  0.2214702  0.0316386 ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "data1 = np.array(\n",
    "    [[5.1,3.5,1.4,0.2],\n",
    "     [4.9,3.0,1.4,0.2],\n",
    "     [4.7,3.2,1.3,0.2],\n",
    "     [4.6,3.1,1.5,0.2],\n",
    "     [5.0,3.6,1.4,0.2]])\n",
    "print(data1)\n",
    "normalized_data = preprocessing.normalize(data1) # Normalisation of array\n",
    "print(normalized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
